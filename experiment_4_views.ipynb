{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33073c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from globals import *\n",
    "import pandas as pd\n",
    "from multiviewstacking import MultiViewStacking\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4049d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file.\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Encode labels into integers.\n",
    "le = LabelEncoder()\n",
    "df[\"class\"] = le.fit_transform(df[\"class\"])\n",
    "\n",
    "# Get features, class\n",
    "y = df[\"class\"]\n",
    "\n",
    "# Drop the label.\n",
    "X = df.drop([\"class\"], axis = 1)\n",
    "\n",
    "# Get column names.\n",
    "colnames = list(X.columns)\n",
    "\n",
    "# Get column indices for each view.\n",
    "ind_v1 = [colnames.index(x) for x in colnames if \"v1_\" in x]\n",
    "ind_v2 = [colnames.index(x) for x in colnames if \"v2_\" in x]\n",
    "ind_v3 = [colnames.index(x) for x in colnames if \"v3_\" in x]\n",
    "ind_v4 = [colnames.index(x) for x in colnames if \"v4_\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f1c8b0-2998-4406-b25b-8c0be9bb9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff576fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Initialize ---\n",
    "results = None\n",
    "activated = False\n",
    "\n",
    "# Folder for results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_dir = Path(DATASET_PATH + f\"results/{timestamp}/\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize confusion matrix accumulators\n",
    "labels = le.classes_\n",
    "n_classes = len(labels)\n",
    "cm_sum = {\n",
    "    \"MVS\": np.zeros((n_classes, n_classes), dtype=float),\n",
    "    \"V1\": np.zeros((n_classes, n_classes), dtype=float),\n",
    "    \"V2\": np.zeros((n_classes, n_classes), dtype=float),\n",
    "    \"V3\": np.zeros((n_classes, n_classes), dtype=float),\n",
    "    \"V4\": np.zeros((n_classes, n_classes), dtype=float),\n",
    "    \"AGG\": np.zeros((n_classes, n_classes), dtype=float)\n",
    "}\n",
    "\n",
    "# --- Run experiments ---\n",
    "for i in trange(ITERATIONS, desc=\"Running experiments\"):\n",
    "    \n",
    "    curr_it = 1 + i\n",
    "    print(f\"\\nIteration {curr_it}\")\n",
    "\n",
    "    # Set random seeds\n",
    "    random_seed = 100 + curr_it\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    # Split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=PCT_TRAIN, stratify=y, random_state=random_seed\n",
    "    )\n",
    "\n",
    "    # RandomForest parameters\n",
    "    rf_params = dict(n_estimators=NTREES, random_state=123, n_jobs=NUMCORES)\n",
    "\n",
    "    # Create models\n",
    "    m_v1 = RandomForestClassifier(**rf_params)\n",
    "    m_v2 = RandomForestClassifier(**rf_params)\n",
    "    m_v3 = RandomForestClassifier(**rf_params)\n",
    "    m_v4 = RandomForestClassifier(**rf_params)\n",
    "    m_meta = RandomForestClassifier(**rf_params)\n",
    "\n",
    "    model = MultiViewStacking(\n",
    "        views_indices=[ind_v1, ind_v2, ind_v3, ind_v4],\n",
    "        first_level_learners=[m_v1, m_v2, m_v3, m_v4],\n",
    "        meta_learner=m_meta\n",
    "    )\n",
    "\n",
    "    # Train Multi-View Stacking model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # --- Evaluate MVS model ---\n",
    "    preds_mvs = le.inverse_transform(model.predict(X_test))\n",
    "    gt = le.inverse_transform(y_test)\n",
    "\n",
    "    if not activated:\n",
    "        results = classification_metrics_row(curr_it, \"MVS\", preds_mvs, gt)\n",
    "        activated = True\n",
    "    else:\n",
    "        results = classification_metrics_row(curr_it, \"MVS\", preds_mvs, gt, df=results)\n",
    "\n",
    "    cm_sum[\"MVS\"] += confusion_matrix(gt, preds_mvs, labels=labels)\n",
    "\n",
    "    # --- Individual view models ---\n",
    "    fitted_v1 = model.fitted_first_level_learners_[0]\n",
    "    fitted_v2 = model.fitted_first_level_learners_[1]\n",
    "    fitted_v3 = model.fitted_first_level_learners_[2]\n",
    "    fitted_v4 = model.fitted_first_level_learners_[3]\n",
    "\n",
    "    preds_v1 = le.inverse_transform(fitted_v1.predict(X_test.values[:, ind_v1]))\n",
    "    results = classification_metrics_row(curr_it, \"V1\", preds_v1, gt, df=results)\n",
    "    cm_sum[\"V1\"] += confusion_matrix(gt, preds_v1, labels=labels)\n",
    "\n",
    "    preds_v2 = le.inverse_transform(fitted_v2.predict(X_test.values[:, ind_v2]))\n",
    "    results = classification_metrics_row(curr_it, \"V2\", preds_v2, gt, df=results)\n",
    "    cm_sum[\"V2\"] += confusion_matrix(gt, preds_v2, labels=labels)\n",
    "\n",
    "    preds_v3 = le.inverse_transform(fitted_v3.predict(X_test.values[:, ind_v3]))\n",
    "    results = classification_metrics_row(curr_it, \"V3\", preds_v3, gt, df=results)\n",
    "    cm_sum[\"V3\"] += confusion_matrix(gt, preds_v3, labels=labels)\n",
    "\n",
    "    preds_v4 = le.inverse_transform(fitted_v4.predict(X_test.values[:, ind_v4]))\n",
    "    results = classification_metrics_row(curr_it, \"V4\", preds_v4, gt, df=results)\n",
    "    cm_sum[\"V4\"] += confusion_matrix(gt, preds_v4, labels=labels)\n",
    "\n",
    "    # --- Aggregated model (single view all features) ---\n",
    "    m_agg = RandomForestClassifier(**rf_params)\n",
    "    m_agg.fit(X_train, y_train)\n",
    "    preds_agg = le.inverse_transform(m_agg.predict(X_test))\n",
    "    results = classification_metrics_row(curr_it, \"AGG\", preds_agg, gt, df=results)\n",
    "    cm_sum[\"AGG\"] += confusion_matrix(gt, preds_agg, labels=labels)\n",
    "\n",
    "\n",
    "# --- Compute and save normalized average confusion matrices ---\n",
    "for model_name, cm in cm_sum.items():\n",
    "    # Average over iterations\n",
    "    cm_avg = cm / ITERATIONS\n",
    "    \n",
    "    # Row-normalize (each row sums to 1)\n",
    "    cm_norm = cm_avg / cm_avg.sum(axis=1, keepdims=True)\n",
    "    cm_norm = np.nan_to_num(cm_norm)  # Handle potential division by zero\n",
    "    \n",
    "    # Save normalized matrix as CSV\n",
    "    df_cm = pd.DataFrame(cm_norm, index=labels, columns=labels)\n",
    "    csv_path = results_dir / f\"confusion_matrix_{model_name}_AVG_norm.csv\"\n",
    "    df_cm.to_csv(csv_path)\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                xticklabels=labels, yticklabels=labels, cbar=True,\n",
    "                vmin=0, vmax=1)\n",
    "    plt.title(f\"Row-Normalized Average Confusion Matrix - {model_name}\", fontsize=14)\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig(results_dir / f\"confusion_matrix_{model_name}_AVG_norm.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Save overall results summary\n",
    "results_path = results_dir / \"results_summary.csv\"\n",
    "results.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\"Done! Results saved in: {results_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735018d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
